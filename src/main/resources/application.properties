#######################################
#	DISABLE NULL ON JSON
#######################################
spring.jackson.default-property-inclusion = NON_NULL

server.port=9089
spring.application.name=eds-ms-dataprocessor
server.servlet.context-path=/

####### APPLICATION MONITORING ################
info.app.name=EDS Data Processor Microservice
info.app.description=EDS Data Processor Microservice for FSE.
info.app.version=1.0.0

management.server.port=9089
management.endpoints.web.base-path=/
management.endpoints.web.path-mapping.live=status
management.endpoints.web.path-mapping.health=health-ready
management.endpoint.metrics.enabled=true
management.endpoint.prometheus.enabled=true
management.endpoints.web.path-mapping.prometheus=metrics
management.endpoints.web.path-mapping.metrics=actuator
management.endpoints.web.exposure.include=health,metrics,prometheus,live,ready,env,info
management.health.db.enabled=true
management.endpoint.health.show-details=always
####### APPLICATION MONITORING ################

####### LOGGING OUTPUT FORMAT ############
# Must be one of console or json
#######################################
log.output.format=console
validation.file-max-size=1000
log.kafka-log.enable=true
#######################################
#  KAFKA 
#######################################
#### KAFKA CONNECTION SETTINGS ##########
spring.sleuth.messaging.kafka.enabled=false
kafka.properties.security.protocol=SASL_SSL
kafka.properties.sasl.mechanism=SCRAM-SHA-256
kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username='${kafka_user-it-dgc-certificate-service}' password='${kafka_password-it-dgc-certificate-service}';
kafka.properties.ssl.truststore.location=/config/resources/security/truststore.jks
kafka.properties.ssl.truststore.password=${TRUST_JKS_PASSWORD}
kafka.enablessl=true

####### KAFKA PRODUCER SETTINGS ################
kafka.bootstrap-servers=${KAFKA_HOST}:${KAFKA_PORT1},${KAFKA_HOST}:${KAFKA_PORT2},${KAFKA_HOST}:${KAFKA_PORT3}
kafka.producer.client-id=springboot-eds-srv-dataprocessor
kafka.producer.retries=5
kafka.producer.key-serializer= org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value-serializer= org.apache.kafka.common.serialization.StringSerializer
kafka.producer.transactional.id=edsdataprocessor.tx.
kafka.producer.enable.idempotence=true
kafka.producer.ack=all
 
###### KAFKA TOPIC #########
kafka.ingestor-publish.topic.low-priority=MDS-SA-0004_FU_002_DP-PUBLICATION_LOW
kafka.ingestor-publish.topic.medium-priority=MDS-SA-0004_FU_002_DP-PUBLICATION_MEDIUM
kafka.ingestor-publish.topic.high-priority=MDS-SA-0004_FU_002_DP-PUBLICATION_HIGH
kafka.dataprocessor.generic.topic=MDS-SA-0004_FU_002_DP-GENERICS
kafka.ingestor-publish.deadletter.topic=MDS-SA-0004_FU_002_DP-PUBLICATION-DLT
kafka.statusmanager.topic=MDS-SA-0004_FU_002_STATUS
kafka.log.base-topic=MDS-SA-0004_FU_002_LOG

####### KAFKA DEAD LETTER #####################
kafka.consumer.dead-letter-exc={'it.finanze.sanita.fse2.ms.edssrvdataprocessor.exceptions.BlockingException','java.lang.NullPointerException','it.finanze.sanita.fse2.ms.edssrvdataprocessor.exceptions.DocumentAlreadyExistsException'}
kafka.consumer.temporary-exc={'java.net.ConnectException','java.net.SocketException'}
kafka.retry=3

####### KAFKA CONSUMER ########################

kafka.consumer.bootstrap-servers=${KAFKA_HOST}:${KAFKA_PORT1},${KAFKA_HOST}:${KAFKA_PORT2},${KAFKA_HOST}:${KAFKA_PORT3}
kafka.consumer.client-id=springboot-eds-srv-dataprocessor-client
kafka.consumer.client-id.low=springboot-eds-srv-dataprocessor-client-low
kafka.consumer.client-id.medium=springboot-eds-srv-dataprocessor-client-medium
kafka.consumer.client-id.high=springboot-eds-srv-dataprocessor-client-high
kafka.consumer.client-id.replace=springboot-eds-srv-dataprocessor-client-replace
kafka.consumer.group-id-publish=fse-eds-srv-dataprocessor-publish-group
kafka.consumer.key-deserializer= org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.auto-offset-reset=earliest
kafka.consumer.isolation.level=read_committed
kafka.consumer.auto-commit=false
event.topic.auto.start=true
kafka.retry=3

######OPENAPI#####################################
springdoc.swagger-ui.path=/openapi/ui

docs.info.contact.name=Mario Rossi
docs.info.contact.mail=mariorossi@ibm.com
docs.info.contact.url=www.example.com
docs.info.termsOfService=www.terms.com
docs.info.summary=Data Processor Module for documents towards EDS
docs.info.description=The Data Processor Module for EDS
docs.info.api-id=1
docs.info.title=EDS Data Processor Microservice

#######################################
#			DATASOURCE DB
#######################################
data.mongodb.uri=mongodb://${MONGO_USER}:${MONGO_PASSWORD}@<mondodb_hostname>:<mondodb_port>/<mondodb_dbname>

#######################################
#   MICROSERVICES URL CFG
#######################################
ms.url.eds-srv-data-quality.host=
ms.url.eds-srv-query.host=
